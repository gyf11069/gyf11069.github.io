---
title: 计算机各种字符集的发展史
date: 2022-03-26 23:36:18
permalink: /pages/a9413c/
categories:
  - 十万个为什么
  - Java
tags:
  - 
---

## 计算机各种字符集的发展史(转发)

关于字符编码的概念太多太杂，当例如ASCII、 GB2312、 Unicode、UTF-8、 UTF-16、编码、解码等诸多名词一股脑的堆上来时,确实容易让人迷糊，为了把这些个问题都能讲清楚，我们今天换一种讲法，**不讲编程，只讲故事**，从时间轴上梳理计算机在不同语言国家不断发展的历史，来彻底搞清楚这些概念。

计算机自己能理解的"语言”是二进制数，最小的信息标识是二进制位，8 个二进制位表示一个字节；而我们人类所能理解的语言文字则是一套由英文字母、 汉语汉字、标点符号字符、阿拉伯数字等等很多的字符构成的字符集。如果要让计算机来按照人类的意愿进行工作，则必须把人类所使用的这些字符集转换为计算机所能理解的二级制码，这个过程就是编码，他的逆过程称为解码。

最开始计算机在美国发明使用，需要编码的字符集并不是很大，无外乎英文字母、数字和一些简单的标点符号，因此采用了一种单字节编码系统。 在这套编码规则中，人们将所需字符集中的字符一一映射到128个二进制数上，这 128 个二进制数是最高位为 0，利用剩余低 7 位组成`00000000~01111111 (0X00~0X7F)` 。`0X00`到`0X1F`共 32 个二进制数来对控制字符或通信专用字符(如`LF`换行、`DEL`删除、`BS`退格)编码，`0X20`到`0X7F`共 96 个二进制数来对阿拉伯数字、英文字母大小写和下划线、括号等符号进行编码。**将这套字符集映射到`0X00~0X7F`二进制码的过程就称为基础ASCII编码**，通过这个编码过程，计算机就将人类的语言转化为自己的语言存储了起来，反之从磁盘中读取二级制数并转化为字母数字等字符以供显示的过程就是解码了。

随着计算机被迅速推广使用，欧洲的非英语国家的人们发现这套由美国人设计的字符集不够用了，比如一-些带重音的字符、希腊字母等都不在这个字符集中，于是扩充了`ASCII`编码规则，将原本为 0 的最高位改为 1 ，因此扩展出了`10000000~11111111 (0X80~0XFF) `这 128 个二进制数。这其中，最优秀的扩展方案是`ISO 8859-1`，通常称之为`Latin-1`。`Latin-1`利用`128~255`这 128 个二进制数，包括了足够的附加字符集来涵盖基本的西欧语言，同时在`0~127`的范围内兼容`ASCII`编码规则。

随着使用计算机的国家越来越多，自然而然需要编码的字符集就越来越庞大，早先的`ASCII`编码字符集由于受到单字节的限制，其容量就远远不够了，比方说面对成千上万的汉字,其压力可想而知。因此中国国家标准总局发布了一套《信息交换用汉字编码字符集》的国家标准，其标准号就是`GB2312-1980`。 这个字符集共收入汉字 6763 个和非汉字图形字符682 个，采用两个字节对字符集进行编码，并向下兼容`ASCII`编码方式。简言之，整个字符集分成 94 个区，每区有 94 个位，分别用一个字节对应表示相应的区和位。每个区位对应一个字符，因此可用所在的区和位来对汉字进行两字节编码。再后来生僻字、繁体字及日韩汉字也被纳入字符集，就又有了后来的`GBK`字符集及相应的编码规范，`GBK`编码规范也是向下兼容`GBK2312`的。

在中国发展的同时，计算机在全世界各个国家不断普及,不同的国家地区都会开发出自己的一套编码系统，因此编码系统五花八门，这时候问题就开始凸显了，特别是在互联网通信的大环境下，装有不同编码系统的计算机之间通信就会彼此不知道对方在"说”些什么，按照 A 编码系统的编码方式将所需字符转换成二进制码后，在 B 编码系统的计算机上解码是无法得到原始字符的，相反会出现一些出人意料的古怪字符，这就是所谓的乱码。

那么统一字符编码的需求就迫切摆在了大家眼前，为了实现跨语言、跨平台的文本转换和处理需求，ISO 国际标准化组织提出了`Unicode`的新标准，这套标准中包含了`Unicode`字符集和一套编码规范。`Unicode`字符集涵盖 了世界上所有的文字和符号字符，`Unicode`编码方案为字符集中的每一个字符指定了统-且唯一-的 二进制编码，这就能彻底解决之前不同编码系统的冲突和乱码问题。这套编码方案简单来说是这样的：编码规范中含有17个组(称为平面)，每一个组含有 65536 个码位 (例如组 0 就是`0X0000~0FFF`) ，每一个码位就唯一对应一个字符，大部分的字符都位于字符集平面 0 的码位中，少量位于其他平面。

既然提到了`Unicode`编码，那么常常与之相伴的`UTF-8`，`UTF-16`编码方案又是什么?实到目前为止我们都一致混淆了两个概念，即字符代码和字符编码，字符代码是特定字符在某个字符集中的序号，而字符编码是在传输、存储过程当中用于表示字符的以字节为单位的二进制序列。ASCII 编码系统中，字符代码和字符编码是一致的，比如字符 A，在`ASCII`字符集中的序号，也就是所谓的字符代码是 65，存储在磁盘中的二进制比特序列是 `01000001` (`0X41`, 十进制也是 65 )，另外的，如在`GB2312`编码系统中字符代码和字符编码的值也是一致的， 所以无形之中我们就忽略了二者的差异性。而在`Unicode`标准中，我们目前使用的是`UCS-4`，即字符集中每一个字符的字符代码都是用 4 个字节来表示，其中字符代码`0~ 127`兼容`ASCII`字符集，一般的通用汉字的字符代码也都集中在 65535 之前，使用大于 65535 的字符代码，即需要超过两个字节来表示的字符代码是比较少的。因此，如果仍然依旧采用字符代码和字符编码相一致的编码方式， 那么英语字母、数字原本仅需一个字节编码，目前就需要 4 个字节进行编码，汉字原本仅需两个字节进行编码，目前也需要 4 个字节

进行编码，这对于存储或传输资源而言是很不划算的。因此就需要在字符代码和字符编码间进行再编码，这样就引出了`UTF-8、UTF-16`等编码方式。基于上述需求，`UTF-8`就是针对位于不同范围的字符代码转化成不同长度的字符编码，同时这种编码方式是以字节为单位，并且完全兼容`ASCIl`编码，即`0X00-0X7F`的字符代码和字符编码完全一致, 也是用一个字节来编码`ASCII`字符集，而常用汉字在`Unicode`中的字符代码是`4E00-9FA5`，在文末的对应关系中我们看到是用三个字节来进行汉字字符的编码。`UTF-16`同理， 就是以 16 位二进制数为基本单位对`Unicode`字符集 中的字符代码进行再编码，原理和`UTF-8`一致。

因此，我们可以看出，在目前全球互联的大背景下，`Unicode`字符集和编码方式解决了跨语言、跨平台的交流问题，同时`UTF-8`等编码方式又有效的节约了存储空间和传输带宽，因而受到了极大的推广应用。

### 参考资料

[AscII码 和 unicode码是什么关系](https://www.zhihu.com/question/57461614)

